<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Chaitanya Mitash</title>
  
  <meta name="author" content="Chaitanya Mitash">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chaitanya Mitash</name>
              </p>
              <p>I am a Ph.D Candidate in the Computer Science department at Rutgers, co-advised by professors <a style="color: blue;text-decoration: underline;" href="http://www.abdeslam.net/"> Abdeslam Boularias </a> and <a style="color: blue;text-decoration: underline;" href="http://www.pracsyslab.org/bekris"> Kostas Bekris </a>. My research interests lie in the field of Robotics, Computer Vision and Machine Learning. Specifically, I am working on problems related to perception for Robotic Manipulation. 

              During my PhD, I did internships with Microsoft Hololens, Redmond, WA where I worked on semantic segmentation for mixed reality applications and at <a href="https://www.amazonrobotics.com/">Amazon Robotics, North Reading, MA</a> where I worked on task-driven perception for manipulation.

              Before graduate school, I worked as a software engineer in the R&D divisions of Samsung Electronics and Tejas Networks in the embedded software domain. I received my B.E. degree in Computer Science from Birla Institute of Technology, Mesra in 2012.
              </p>
              <p style="text-align:center">
                <a href="mailto:mitash.chaitanya@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Chaitanya_Mitash_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=6UhCCYgAAAAJ&hl=en#">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/cmitash">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/chaitanya-mitash-65823a21">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/task_driven.png' width="160"></div>
                <img src='images/task_driven.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://robotics.cs.rutgers.edu/task-driven-perception/">
                <papertitle>Task-driven Perception and Manipulation for Constrained Placement of Unknown Objects</papertitle>
              </a>
              <br>
              <strong>Chaitanya Mitash</strong>, Rahul Shome, Bowen Wen, Abdeslam Boularias, Kostas Bekris
              <br>
        <em>IEEE Robotics and Automation Letters (RA-L) & IROS</em>, 2020  
              <br>
              <a href="https://robotics.cs.rutgers.edu/task-driven-perception/">project page</a>/
              <a href="https://arxiv.org/pdf/2006.15503.pdf">arXiv</a>/
              <a href="data/ral20_supplementary_material.pdf">supplementary material</a>
              <p></p>
              <p>An integrated perception and manipulation planning pipeline with a dynamic object representation, demonstrating high success rate and efficiency in solving pick-and-constrained placement of previously unseen objects.</p>
            </td>
          </tr>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/se3_tracknet.gif' width="160"></div>
                <img src='images/se3_tracknet.gif' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>se(3)-TrackNet: Data-driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic Domains</papertitle>
              </a>
              <br>
              Bowen Wen, <strong>Chaitanya Mitash</strong>, Baozhang Ren and Kostas Bekris
              <br>
        <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2020  
              <br>
              <a href="">project page (Coming soon...)</a>/
              <a href="">arXiv (Coming soon...)</a>
              <p></p>
              <p>Learning in simulation to predict residual poses for object models in RGB-D sequences.</p>
            </td>
          </tr>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/safe_picking.png' width="160"></div>
                <img src='images/safe_picking.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Safe and Effective Picking Paths in Clutter given Discrete Distributions of Object Poses</papertitle>
              </a>
              <br>
              Rui Wang, <strong>Chaitanya Mitash</strong>, Shiyang Lu, Daniel Boehm, Kostas E. Bekris
              <br>
        <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2020  
              <br>
              <a href="">project page (Coming soon...)</a>/
              <a href="">arXiv (Coming soon...)</a>
              <p></p>
              <p>A perception and motion planning framework that considers the uncertainty in object poses to generate picking plans that minimizes the chance of collision and maximizes the likelihood of success.</p>
            </td>
          </tr>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/adaptive_hand_pose.png' width="160"></div>
                <img src='images/adaptive_hand_pose.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2003.03518.pdf">
                <papertitle>Robust, Occlusion-aware Pose Estimation for Objects Grasped by Adaptive Hands</papertitle>
              </a>
              <br>
              Bowen Wen, <strong>Chaitanya Mitash</strong>, Sruthi Soorian, Andrew Kimmel, Avishai Sintov and Kostas Bekris
              <br>
        <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020  
              <br>
              <a href="https://arxiv.org/pdf/2003.03518.pdf">arXiv</a>/
              <a href="https://github.com/wenbowen123/icra20-hand-object-pose/">code</a>
              <p></p>
              <p>Simultaneous pose estimation of robot hand and the hand-held object via 3d pointset registration while considering physical consistency.</p>
            </td>
          </tr>  

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/pointing.png' width="160"></div>
                <img src='images/pointing.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1912.06602">
                <papertitle>That and There: Judging the Intent of Pointing Actions with Robotic Arms</papertitle>
              </a>
              <br>
              Malihe Alikhani, Baber Khalid, Rahul Shome, <strong>Chaitanya Mitash</strong>, Kostas Bekris, Matthew Stone
              <br>
        <em>AAAI Conference on Artificial Intelligence</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/1912.06602">arXiv</a>
              <p></p>
              <p>Presents a set of interpretive principles for how a robotic arm can use pointing actions to communicate task information to people. The evaluation distinguishes two classes of pointing actions that arise in pick-and- place tasks: referential pointing (identifying objects) and locating pointing (identifying locations).</p>
            </td>
          </tr>  

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/corl.png' width="160"></div>
                <img src='images/corl.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1910.04953.pdf">
                <papertitle>Scene-level Pose Estimation for Multiple Instances of Densely Packed Objects</papertitle>
              </a>
              <br>
              <strong>Chaitanya Mitash</strong>, Bowen Wen, Kostas Bekris, and Abdeslam Boularias
              <br>
        <em>Conference on Robot Learning (CoRL)</em>, 2019  
              <br>
              <a href="https://arxiv.org/pdf/1910.04953.pdf">arXiv</a>
        /
              <a href="https://github.com/cmitash/multi-instance-pose-estimation">code</a>
              <p></p>
              <p>Introduces key machine learning operations for joint 6D pose estimation of multiple instances of objects in challenging scenarios by learning over just simulated data. </p>
            </td>
          </tr>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/packing.png' width="160"></div>
                <img src='images/packing.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://robotics.cs.rutgers.edu/robot-bin-packing/">
                <papertitle>Towards Robust Product Packing with a Minimalistic End-Effector</papertitle>
              </a>
              <br>
              Rahul Shome, Wei N. Tang, Changkyu Song, <strong>Chaitanya Mitash</strong>, Chris Kourtev, Jingjin Yu, Abdeslam Boularias, and Kostas Bekris
              <br>
        <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2019  
              <br>
              <a href="https://robotics.cs.rutgers.edu/robot-bin-packing/">project page</a>
        /
              <a href="https://arxiv.org/abs/1903.00984">arXiv</a>
              <p></p>
              <p>Introduces manipulation primitives (toppling, adaptive pushing and fine-correction) to achieve robust bin packing with a simple vacuum-based end-effector. A robotic system is develeoped and large-scale experiments are performed to demonstrate its efficacy.</p>
            </td>
          </tr>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/wsl.png' width="160"></div>
                <img src='images/wsl.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1806.06888">
                <papertitle>Learning Object Localization and 6D Pose Estimation from Simulation and Weakly Labeled Real Images</papertitle>
              </a>
              <br>
              Jean-Philippe Mercier, <strong>Chaitanya Mitash</strong>, Philippe Giguere and Abdeslam Boularias
              <br>
        <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2019  
              <br>
              <a href="https://arxiv.org/abs/1806.06888">arXiv</a>
              <p></p>
              <p>Sim2real adaptation of object detector via weakly labeled images and utilization of activation maps for 6d object pose estimation.</p>
            </td>
          </tr>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/stocs.gif' width="160"></div>
                <img src='images/stocs.gif' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1805.06324">
                <papertitle>Robust 6D Object Pose Estimation with Stochastic Congruent Sets</papertitle>
              </a>
              <br>
              <strong>Chaitanya Mitash</strong>, Abdeslam Boularias and Kostas Bekris
              <br>
        <em>British Machine Vision Conference (BMVC)</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1805.06324">arXiv</a>
        /
              <a href="https://github.com/cmitash/model_matching">code</a>
              <p></p>
              <p>A soft segmentation output can be used to guide sampling-based pointset registration to retrieve object poses.</p>
            </td>
          </tr> 

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/ijrr.png' width="160"></div>
                <img src='images/ijrr.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://physimpose.com">
                <papertitle>Physics-based Scene-level Reasoning for Object Pose Estimation in Clutter</papertitle>
              </a>
              <br>
              <strong>Chaitanya Mitash</strong>, Abdeslam Boularias and Kostas Bekris
              <br>
        <em>International Journal of Robotics Research (IJRR)</em>, 2019
              <br>
              <a href="http://physimpose.com">project page</a>
        /
              <a href="https://arxiv.org/pdf/1806.10457.pdf">arXiv</a>
              <p></p>
              <p>Integrates the self-supervised learning via physics simulation with online scene-level reasoning.</p>
            </td>
          </tr> 

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/mcts.gif' width="160"></div>
                <img src='images/mcts.gif' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://physimpose.com">
                <papertitle>Improving 6D Pose Estimation of Objects in Clutter via Physics-aware Monte Carlo Tree Search</papertitle>
              </a>
              <br>
              <strong>Chaitanya Mitash</strong>, Abdeslam Boularias and Kostas Bekris
              <br>
        <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2018  
              <br>
              <a href="http://physimpose.com">project page</a>
        /
              <a href="https://arxiv.org/abs/1710.08577">arXiv</a>
              <p></p>
              <p>A combinatorial search algorithm to generate, evaluate and select physically-consistent scene hypothesis from independent object detections.</p>
            </td>
          </tr>

          <!-- Paper -->

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/physim.gif' width="160"></div>
                <img src='images/physim.gif' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://physimpose.com">
                <papertitle>A Self-supervised Learning System for Object Detection using Physics Simulation and Multi-view Pose Estimation</papertitle>
              </a>
              <br>
              <strong>Chaitanya Mitash</strong>, Kostas Bekris and Abdeslam Boularias
              <br>
        <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2017  
              <br>
              <a href="http://physimpose.com">project page</a>
        /
              <a href="https://arxiv.org/pdf/1703.03347.pdf">arXiv</a>
        /
              <a href="https://github.com/cmitash/physim-dataset-generator">code</a>
              <p></p>
              <p>Physically-realistic simulation allows better training for object detection in robotics setup and can bootstrap a self-learning process to automatically collect and label real images and improve the detector over time.</p>
            </td>
          </tr> 
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Workshop & Talks</heading><br><br>
              <a href="https://sites.google.com/view/rsspioneers2019/home">Robotics Science and Systems (RSS) Pioneers, 2019</a> (<a href="data/RSS-Pioneers-Chaitanya.pptx">Talk</a> / <a href="http://rss2019.informatik.uni-freiburg.de/RSS_Pioneers_2019_Camera_Ready/24.pdf">Abstract</a>)<br>
              <a href="http://cmp.felk.cvut.cz/sixd/workshop_2018/">4th International Workshop on Recovering 6D Object Pose, ECCV, 2018</a> (<a href="data/bmvc18.pdf">Poster</a>)<br>
              <a href="https://prisma.dieti.unina.it/index.php/events/552-robotics-for-logistics-in-warehouses-and-environments-shared-with-humans">Robotics for logistics in warehouses and environments shared with humans, IROS, 2018</a> (<a href="http://www.refills-project.eu/images/events/IROS2018/pdf/Shome.pdf">Abstract</a>)<br>
              <a href="https://ewh.ieee.org/soc/ras/conf/fullysponsored/icra/2017/www.icra2017.org/conference/workshops-and-tutorials.html">Warehouse Picking Automation Workshop, ICRA, 2017</a> (<a href="data/icra17_workshop.pdf">Abstract</a>)<br>
              <a href="https://nerc2017.ccis.northeastern.edu">Northeast Robotics Colloquium (NERC), 2017</a> (<a href="data/nerc.pdf">Poster</a>)
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading><br><br>
              (Reviewer) Conference on Neural Information Processing Systems/NeurIPS (2019, 2020)<br>
              (Reviewer) IEEE Robotics and Automation Letters/RA-L (2018, 2020)<br>
              (Reviewer) IEEE International Conference on Intelligent Robots and Systems/IROS (2017, 2018, 2019, 2020)<br>
              (Reviewer) IEEE International Conference on Robotics and Automation/ICRA (2018, 2019)<br>
              (Reviewer) Conference on Computer Vision and Pattern Recognition/CVPR 2019<br>
              (Meta-reviewer) Robotics Science and Systems (RSS) Pioneers 2020<br>
              (Assisted Review) Robotics Science and Systems (RSS) 2020<br>
              (Assisted Review) The Workshop on the Algorithmic Foundations of Robotics/WAFR 2020<br>
              (Assisted Review) Conference on Robot Learning/CoRL 2019<br>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
  <br><br><br>
  <a href="https://jonbarron.info">Website template copied from here.</a>
</body>

</html>
